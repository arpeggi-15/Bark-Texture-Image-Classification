{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "193f02f1",
      "metadata": {
        "id": "193f02f1"
      },
      "source": [
        "**Bark Texture Images Classification**\n",
        "\n",
        "The Dataset used in this notebook can be downlaoded from this page https://www.kaggle.com/datasets/saurabhshahane/barkvn50\n",
        "\n",
        "From the description of images we can see that there are 5578 images of 50 categories of bark texture. We need to build a model that can classify these images into appropriate category.\n",
        "\n",
        "Once you download you will find a zip file and upon unzipping you will find a folder named \"BarkVN-50\". Under this folder, there is a folder named  \"BarkVN-50_mendeley\" in which there are 50 folders with each having images in it for each category of bark texture. So take the folder \"BarkVN-50_mendeley\" and move it to your current working directory \n",
        "\n",
        "Now let's first import all the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f5395528",
      "metadata": {
        "id": "f5395528"
      },
      "outputs": [],
      "source": [
        "##Importing Required Libraries\n",
        "\n",
        "import os \n",
        "import shutil\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import random \n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras.applications import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5de2c5f5",
      "metadata": {
        "id": "5de2c5f5"
      },
      "source": [
        "The \"BarkVN-50_mendeley\" folder is renamed as \"bark_dataset\".\n",
        "\n",
        "Now let's have a look how many images per category we have "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7c6961b",
      "metadata": {
        "id": "e7c6961b"
      },
      "outputs": [],
      "source": [
        "for dirpath, dirnames, filenames in os.walk(\"bark_dataset/\"):\n",
        "    print(f\"there are {len(dirnames)} directories and {len(filenames)} files in '{dirpath}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cba2662",
      "metadata": {
        "id": "0cba2662"
      },
      "source": [
        "The images for each category has been renamed as category1.JPG, category2.JPG. For example images in Acacia folder are named Acacia1.JPG., Acacia2.JPG .....etc.\n",
        "\n",
        "    Since , the images of different categories can have same name as they are named in the format of IMG_ 3587.JPG. \n",
        "    So, it can be a problem while moving the images in different folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f19c7f78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "f19c7f78",
        "outputId": "9bfb26f6-1ee9-4b4c-9520-f8a9f7760918"
      },
      "outputs": [],
      "source": [
        "all_categories = os.listdir(\"bark_dataset/\")\n",
        "\n",
        "for category in sorted(all_categories):\n",
        "    all_images = os.listdir(\"bark_dataset/\" + category + \"/\" )\n",
        "    i = 1\n",
        "    for image in all_images:\n",
        "        os.rename('bark_dataset/'+ category + \"/\" + image , 'bark_dataset/' + category + \"/\" + category + str(i) + \".JPG\")\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c266f7db",
      "metadata": {
        "id": "c266f7db"
      },
      "source": [
        "##Train-Test Splitting\n",
        "\n",
        "For that I have created a train and est folder in my current working directory. In train folder, 50 folders have been created\n",
        "for each category of images with the same name as it was in downloaded data \n",
        "and have been put all the training data for each category in that same specific category folder. For example\n",
        "the training data for Acacia category is kept in \"train/Acacia/\".\n",
        "\n",
        "Same procedure has been followed for test folder.  For example\n",
        "the testing data for Acacia category is kept in \"test/Acacia/\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abe7d55e",
      "metadata": {
        "id": "abe7d55e"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"train\")\n",
        "for category in sorted(all_categories):\n",
        "    os.makedirs(\"train/\" + category )\n",
        "    all_images = os.listdir(\"bark_dataset/\" + category + \"/\")\n",
        "    for image in random.sample(all_images, int(0.8 * len(all_images))):\n",
        "        shutil.move(\"bark_dataset/\" + category + \"/\" + image, \"train/\" + category + \"/\")\n",
        "\n",
        "        \n",
        "os.makedirs(\"test\")\n",
        "for category in sorted(all_categories):\n",
        "    os.makedirs('test/' + category)\n",
        "    all_images = os.listdir(\"bark_dataset/\" + category + \"/\")\n",
        "    for image in all_images:\n",
        "        shutil.move(\"bark_dataset/\" + category + \"/\" + image, \"test/\" + category + \"/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3becaf95",
      "metadata": {
        "id": "3becaf95"
      },
      "source": [
        "## Creating  a train and test data using ImageDataGenerator \n",
        "\n",
        "We needed to modify the file structure as we did above so that we can create batches of training and testing data to be used in Tensorflow model. \n",
        "Here, the training and testing data is created using ImageDataGenerator. \n",
        "\n",
        "\n",
        "    Note:- normalized pixel values of each image has been used instead of values between 0-255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a07184",
      "metadata": {
        "id": "76a07184",
        "outputId": "d847b5ff-0868-4e84-bd4f-a6cca70b0707"
      },
      "outputs": [],
      "source": [
        "# Set the seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Setup the train and test directories\n",
        "train_dir = \"train/\"\n",
        "test_dir = \"test/\"\n",
        "\n",
        "# Import data from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               batch_size=32, # number of images to process at a time \n",
        "                                               target_size=(224, 224), # convert all images to be 224 x 224\n",
        "                                               class_mode=\"categorical\", \n",
        "                                               seed=42)\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                               batch_size=32,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"categorical\",\n",
        "                                               seed=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a916bd80",
      "metadata": {
        "id": "a916bd80"
      },
      "source": [
        "## Creating a base model in VGGNet and checking the accuracy metrics of this base model\n",
        "\n",
        "Since here, the number of images for different categories are not same but the data is not highly \n",
        "imbalanced, therefore, accuracy will be used for checking the mterics of the base model.\n",
        "\n",
        "    Note:- Base model will be trained for only 5 epochs just to check how the model performs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87d29d1",
      "metadata": {
        "id": "f87d29d1",
        "outputId": "97690fd6-5ad6-48ac-ee5f-6e8346ac5843"
      },
      "outputs": [],
      "source": [
        "#defining the model\n",
        "model_1 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters=10, \n",
        "                         kernel_size=3, \n",
        "                         activation=\"relu\", \n",
        "                         input_shape=(224, 224, 3)), \n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=2, \n",
        "                            padding=\"valid\"),\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"), \n",
        "  tf.keras.layers.MaxPool2D(2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(50, activation=\"softmax\") \n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1 = model_1.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e571ae1f",
      "metadata": {
        "id": "e571ae1f"
      },
      "source": [
        "## Data Visualization  \n",
        "\n",
        "History callback returned is used whenever fit function is performed for visualization of the performace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "882932d9",
      "metadata": {
        "id": "882932d9"
      },
      "outputs": [],
      "source": [
        "def plot_loss_curves(history):\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(len(history.history['loss']))\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(epochs, loss, label = 'training_loss')\n",
        "    plt.plot(epochs, val_loss, label = 'testing_loss')\n",
        "    plt.title(\"loss_curves\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(epochs, accuracy, label = 'training_accuracy')\n",
        "    plt.plot(epochs, val_accuracy, label = 'validation_accuracy')\n",
        "    plt.title(\"accuracy_curves\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc25939b",
      "metadata": {
        "id": "fc25939b"
      },
      "source": [
        "### Visualize the performance of the first base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29bed811",
      "metadata": {
        "id": "29bed811",
        "outputId": "ffa6e504-19e4-4f12-8fc8-27d2dce4bb56"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80892150",
      "metadata": {
        "id": "80892150"
      },
      "source": [
        "## Overfitting Base Model.\n",
        "\n",
        "To prevent overfitting, data augmentation and dropout is simultaneously is used in the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95654117",
      "metadata": {
        "id": "95654117",
        "outputId": "68a77ff3-945b-4ea1-cd00-85e3667fa556"
      },
      "outputs": [],
      "source": [
        "train_datagen_aug = ImageDataGenerator(rescale = 1./255, \n",
        "                                   horizontal_flip = True, \n",
        "                                   vertical_flip = True,\n",
        "                                   height_shift_range = 0.2, \n",
        "                                   width_shift_range = 0.2)\n",
        "\n",
        "\n",
        "train_data_aug = train_datagen_aug.flow_from_directory(train_dir, \n",
        "                                                  batch_size = 32, \n",
        "                                                  target_size = (224, 224), \n",
        "                                                  class_mode = 'categorical', \n",
        "                                                  seed = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab0d20f5",
      "metadata": {
        "id": "ab0d20f5"
      },
      "source": [
        "## New Model \n",
        "\n",
        "This model is same as the base model but has a dropout layer before maxpool layer and is trained on augmented data for more epochs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5640de3",
      "metadata": {
        "id": "f5640de3",
        "outputId": "6dbb0fe3-0370-4279-c524-6e7e567293ab"
      },
      "outputs": [],
      "source": [
        "model_2 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters = 10, kernel_size = 3, input_shape = (224, 224, 3), activation = 'relu'), \n",
        "    tf.keras.layers.Conv2D(filters = 10, kernel_size = 3, activation = 'relu'), \n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.MaxPool2D(2, padding = 'valid'),\n",
        "    tf.keras.layers.Conv2D(filters = 10, kernel_size = 3, activation = 'relu'), \n",
        "    tf.keras.layers.Conv2D(filters = 10, kernel_size = 3, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.4), \n",
        "    tf.keras.layers.MaxPool2D(2, padding = 'valid'),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(50, activation = 'softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model_2.compile(loss = 'categorical_crossentropy', \n",
        "               optimizer = tf.keras.optimizers.Adam(), \n",
        "               metrics = [\"accuracy\"])\n",
        "\n",
        "history_2 = model_2.fit(train_data_aug, \n",
        "                       epochs = 15, \n",
        "                       steps_per_epoch = len(train_data_aug),\n",
        "                       validation_data = test_data, \n",
        "                       validation_steps  = len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a277420",
      "metadata": {
        "id": "0a277420"
      },
      "source": [
        "## Visualise the performance of the new model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0be7cb99",
      "metadata": {
        "id": "0be7cb99",
        "outputId": "5d459bef-3b87-488e-a383-5692b8ac577e"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94e43c96",
      "metadata": {
        "id": "94e43c96"
      },
      "source": [
        "## Using Transfer Learning\n",
        "\n",
        "Even though the model has low variance, the model is not performing well because it has very high bias now.\n",
        "\n",
        "    So, Resnet model is used for transfer learning, considering the nature of the problem.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fde1a3e",
      "metadata": {
        "id": "7fde1a3e"
      },
      "outputs": [],
      "source": [
        "def create_model(model_url, num_classes = 50):\n",
        "    #the model url helps to incorporate the architecutre which we want to use in transfer learning. \n",
        "    #using this function you can incorporate any architecture by providing the suitable url.\n",
        "    feature_extractor_layer = hub.KerasLayer(model_url, \n",
        "                                            trainable = False, \n",
        "                                            input_shape = (224, 224, 3))\n",
        "    model = tf.keras.Sequential([\n",
        "        feature_extractor_layer, \n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b007196d",
      "metadata": {
        "id": "b007196d"
      },
      "source": [
        "A dropout of 40 percent before the prediction layer is used and the model is trained for 10 epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9342c2bf",
      "metadata": {
        "id": "9342c2bf",
        "outputId": "ec53dbe0-d660-4404-ada5-b2d0e54e406e"
      },
      "outputs": [],
      "source": [
        "resnet_v2_50_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n",
        "\n",
        "resnet_model = create_model(resnet_v2_50_url)\n",
        "\n",
        "resnet_model.compile(loss = 'categorical_crossentropy', \n",
        "                    optimizer = tf.keras.optimizers.Adam(), \n",
        "                    metrics = ['accuracy'])\n",
        "\n",
        "history_resnet_model = resnet_model.fit(train_data, \n",
        "                                   epochs = 10, \n",
        "                                   steps_per_epoch = len(train_data), \n",
        "                                   validation_data = test_data, \n",
        "                                   validation_steps = len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33cf78ec",
      "metadata": {
        "id": "33cf78ec",
        "outputId": "869dd19f-4c41-4883-9ecf-734d41c1c404"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history_resnet_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7487c974",
      "metadata": {
        "id": "7487c974"
      },
      "source": [
        "    The current resnet_model is giving training accuracy of 98% and validation accuracy of 92%.\n",
        "    So, it is a good model to use and to further predict on unseen data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "2a00a2d9c20f687cf4a7b7dd2f67b33c0e904b939920254d3fdc9af846e3bafb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
